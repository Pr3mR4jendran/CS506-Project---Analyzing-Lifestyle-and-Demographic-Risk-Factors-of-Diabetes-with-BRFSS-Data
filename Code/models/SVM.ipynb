{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2023fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87e9511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory:\n",
      " C:\\CS506-Project---Analyzing-Lifestyle-and-Demographic-Risk-Factors-of-Diabetes-with-BRFSS-Data\\Code\\models \n",
      "\n",
      "Searching for BRFSS_2024_model_ready.csv ...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Current working directory:\\n\", Path().resolve(), \"\\n\")\n",
    "\n",
    "print(\"Searching for BRFSS_2024_model_ready.csv ...\")\n",
    "# Comment to Sara: We already split the data into train and test sets, just import BRFSS_2024_model_ready_train.csv \n",
    "# and BRFSS_2024_model_ready_test.csv directly in the code.\n",
    "for p in Path().resolve().rglob(\"BRFSS_2024_model_ready.csv\"): \n",
    "    print(\"Found at:\", p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6688a83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (362592, 198) Test shape: (90649, 198)\n"
     ]
    }
   ],
   "source": [
    "# Load model-ready BRFSS data\n",
    "# Comment to Sara: We already split the data into train and test sets, just import BRFSS_2024_model_ready_train.csv \n",
    "# and BRFSS_2024_model_ready_test.csv directly in the code.\n",
    "data = pd.read_csv(\n",
    "    \"../../Results/Data Cleaning Logs/BRFSS_2024_model_ready.csv\",\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(\"DIABETE4\", axis=1)\n",
    "y = data[\"DIABETE4\"].astype(int)\n",
    "\n",
    "# Comment to Sara: You can remove this part since we've already split the data into train and test sets\n",
    "# Train / Test split (20% test, stratified by label)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9109a2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(clf, X_test, y_test, title=\"Model\"):\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    if hasattr(clf, \"predict_proba\"):\n",
    "        y_proba = clf.predict_proba(X_test)\n",
    "        ll = log_loss(y_test, y_proba)\n",
    "    else:\n",
    "        y_proba = None\n",
    "        ll = None\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    print(f\"Accuracy:          {acc:.4f}\")\n",
    "    print(f\"Precision (macro): {prec:.4f}\")\n",
    "    print(f\"Recall (macro):    {rec:.4f}\")\n",
    "    print(f\"F1 Score (macro):  {f1:.4f}\")\n",
    "    if ll is not None:\n",
    "        print(f\"Log Loss:          {ll:.4f}\")\n",
    "\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, zero_division=0))\n",
    "    print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e2e6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment to Sara: You can remove this cell since we've already split the data into train and test sets\n",
    "# Separate features and target\n",
    "X = data.drop(\"DIABETE4\", axis=1)\n",
    "y = data[\"DIABETE4\"].astype(int)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f6745f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Baseline Linear SVM ===\n",
      "Accuracy:          0.8366\n",
      "Precision (macro): 0.4768\n",
      "Recall (macro):    0.3712\n",
      "F1 Score (macro):  0.3732\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.13      0.21     13162\n",
      "           3       0.84      0.99      0.91     75226\n",
      "           4       0.00      0.00      0.00      2261\n",
      "\n",
      "    accuracy                           0.84     90649\n",
      "   macro avg       0.48      0.37      0.37     90649\n",
      "weighted avg       0.79      0.84      0.79     90649\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 1681 11481     0]\n",
      " [ 1071 74155     0]\n",
      " [  118  2143     0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Comment to Sara: We've already performed data cleaning and preprocessing, so we can directly use the train and test sets. No need to use StandardScaler\n",
    "# Baseline Linear SVM with scaling\n",
    "baseline_svm = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=False)),\n",
    "    (\"svm\", LinearSVC(random_state=42))\n",
    "])\n",
    "\n",
    "baseline_svm.fit(X_train, y_train)\n",
    "\n",
    "evaluate_model(baseline_svm, X_test, y_test, title=\"Baseline Linear SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c1709a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GridSearchCV...\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best params: {'svm__C': 0.1, 'svm__tol': 0.0001}\n",
      "Best CV Macro-F1: 0.37268136941446756\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Comment to Sara: We've already performed data cleaning and preprocessing, so we can directly use the train and test sets. No need to use StandardScaler\n",
    "# Pipeline for scaling + SVM\n",
    "svm_pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=False)),\n",
    "    (\"svm\", LinearSVC(random_state=42))\n",
    "])\n",
    "\n",
    "# Hyperparameter search space\n",
    "param_grid = {\n",
    "    \"svm__C\": [0.01, 0.1, 1, 10],\n",
    "    \"svm__tol\": [1e-3, 1e-4],\n",
    "}\n",
    "\n",
    "print(\"Starting GridSearchCV...\")\n",
    "\n",
    "grid_svm = GridSearchCV(\n",
    "    svm_pipe,\n",
    "    param_grid,\n",
    "    scoring=\"f1_macro\",\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\", grid_svm.best_params_)\n",
    "print(\"Best CV Macro-F1:\", grid_svm.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0409dfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Tuned Linear SVM Results ===\n",
      "\n",
      "=== Tuned Linear SVM ===\n",
      "Accuracy:          0.8366\n",
      "Precision (macro): 0.4770\n",
      "Recall (macro):    0.3712\n",
      "F1 Score (macro):  0.3732\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.13      0.21     13162\n",
      "           3       0.84      0.99      0.91     75226\n",
      "           4       0.00      0.00      0.00      2261\n",
      "\n",
      "    accuracy                           0.84     90649\n",
      "   macro avg       0.48      0.37      0.37     90649\n",
      "weighted avg       0.79      0.84      0.79     90649\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 1682 11480     0]\n",
      " [ 1070 74156     0]\n",
      " [  118  2143     0]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate tuned SVM on test set\n",
    "best_svm = grid_svm.best_estimator_\n",
    "\n",
    "print(\"\\n=== Tuned Linear SVM Results ===\")\n",
    "evaluate_model(best_svm, X_test, y_test, title=\"Tuned Linear SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e049178",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "# OPTIONAL â€” RBF SVM \n",
    "###############################################\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "rbf_svm = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=False)),\n",
    "    (\"svm\", SVC(kernel=\"rbf\", probability=True, random_state=42))\n",
    "])\n",
    "\n",
    "print(\"RBF SVM model created (not fitted).\")\n",
    "print(\"Prem can run rbf_svm.fit(X_train, y_train) on his machine.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
