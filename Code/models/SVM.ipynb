{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2023fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    log_loss\n",
    ")\n",
    "\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6688a83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (906703, 198)\n",
      "Test shape: (90649, 198)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train = pd.read_csv(\n",
    "    \"../../Data/BRFSS_2024_model_ready_train.csv\",\n",
    "    low_memory=False\n",
    ")\n",
    "test = pd.read_csv(\n",
    "    \"../../Data/BRFSS_2024_model_ready_test.csv\",\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "X_train = train.drop(\"DIABETE4\", axis=1)\n",
    "y_train = train[\"DIABETE4\"].astype(int)\n",
    "\n",
    "X_test = test.drop(\"DIABETE4\", axis=1)\n",
    "y_test = test[\"DIABETE4\"].astype(int)\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9109a2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(clf, X_test, y_test, title=\"Model\"):\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    y_proba = None\n",
    "    ll = None\n",
    "    if hasattr(clf, \"predict_proba\"):\n",
    "        try:\n",
    "            y_proba = clf.predict_proba(X_test)\n",
    "            ll = log_loss(y_test, y_proba)\n",
    "        except Exception:\n",
    "            y_proba = None\n",
    "            ll = None\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    print(f\"Accuracy:          {acc:.4f}\")\n",
    "    print(f\"Precision (macro): {prec:.4f}\")\n",
    "    print(f\"Recall (macro):    {rec:.4f}\")\n",
    "    print(f\"F1 Score (macro):  {f1:.4f}\")\n",
    "    if ll is not None:\n",
    "        print(f\"Log Loss:          {ll:.4f}\")\n",
    "\n",
    "    print(\"\\nClassification Report:\\n\",\n",
    "          classification_report(y_test, y_pred, zero_division=0))\n",
    "    print(\"\\nConfusion Matrix:\\n\",\n",
    "          confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30e2e6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Baseline Linear SVM ===\n",
      "Accuracy:          0.6165\n",
      "Precision (macro): 0.4389\n",
      "Recall (macro):    0.5306\n",
      "F1 Score (macro):  0.4200\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.32      0.57      0.41     13162\n",
      "           3       0.94      0.63      0.76     75226\n",
      "           4       0.05      0.39      0.09      2261\n",
      "\n",
      "    accuracy                           0.62     90649\n",
      "   macro avg       0.44      0.53      0.42     90649\n",
      "weighted avg       0.83      0.62      0.69     90649\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 7521  2268  3373]\n",
      " [15051 47486 12689]\n",
      " [  728   653   880]]\n"
     ]
    }
   ],
   "source": [
    "# Baseline Linear SVM \n",
    "baseline_svm = LinearSVC(random_state=42, max_iter=2000)\n",
    "baseline_svm.fit(X_train, y_train)\n",
    "\n",
    "evaluate_model(baseline_svm, X_test, y_test, title=\"Baseline Linear SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f6745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuned Linear SVM using best hyperparameters \n",
    "tuned_svm = LinearSVC(\n",
    "    random_state=42,\n",
    "    C=10,\n",
    "    tol=1e-3,\n",
    "    max_iter=2000\n",
    ")\n",
    "\n",
    "tuned_svm.fit(X_train, y_train)\n",
    "\n",
    "evaluate_model(tuned_svm, X_test, y_test, title=\"Tuned Linear SVM (C=10, tol=1e-3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c1709a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF SVM (Not executed here)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Parameter grid for RBF SVM\n",
    "rbf_param_grid = {\n",
    "    \"C\": [0.1, 1, 10],\n",
    "    \"gamma\": [\"scale\", 0.01, 0.001]\n",
    "}\n",
    "\n",
    "# Define RBF SVM model\n",
    "rbf_svm = SVC(kernel=\"rbf\", probability=True, random_state=42)\n",
    "\n",
    "print(\"RBF SVM model and parameter grid are set up.\")\n",
    "print(\"Param grid:\", rbf_param_grid)\n",
    "\n",
    "print(\"\\nExample usage for later (Prem can run this):\")\n",
    "print(\"  from sklearn.model_selection import GridSearchCV, StratifiedKFold\")\n",
    "print(\"  cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\")\n",
    "print(\"  grid_rbf = GridSearchCV(rbf_svm, rbf_param_grid, scoring='f1_macro', cv=cv, n_jobs=-1, verbose=2)\")\n",
    "print(\"  grid_rbf.fit(X_train, y_train)\")\n",
    "print(\"  evaluate_model(grid_rbf.best_estimator_, X_test, y_test, title='Tuned RBF SVM')\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febfc319-999a-4044-8948-4e5b16be92ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE PICKLE BUNDLE FOR SVM MODEL (TUNED LINEAR SVM)\n",
    "\n",
    "\n",
    "# 1. Use the tuned Linear SVM as the final model\n",
    "final_svm = tuned_svm  # assumes tuned_svm is already fitted on X_train, y_train\n",
    "\n",
    "# Predictions on test set\n",
    "y_pred = final_svm.predict(X_test)\n",
    "\n",
    "# LinearSVC has no predict_proba, but we can use decision_function scores\n",
    "y_scores = None\n",
    "if hasattr(final_svm, \"decision_function\"):\n",
    "    try:\n",
    "        y_scores = final_svm.decision_function(X_test)\n",
    "    except Exception:\n",
    "        y_scores = None\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "# 2. PCA + separate SVM for 2D decision boundary visualization\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Train a Linear SVM in PCA space (for visualization only)\n",
    "svm_pca = LinearSVC(\n",
    "    random_state=42,\n",
    "    C=final_svm.C,\n",
    "    tol=final_svm.tol,\n",
    "    max_iter=final_svm.max_iter,\n",
    ")\n",
    "svm_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "# Meshgrid over PCA space\n",
    "x_min, x_max = X_train_pca[:, 0].min() - 1, X_train_pca[:, 0].max() + 1\n",
    "y_min, y_max = X_train_pca[:, 1].min() - 1, X_train_pca[:, 1].max() + 1\n",
    "\n",
    "xx, yy = np.meshgrid(\n",
    "    np.linspace(x_min, x_max, 200),\n",
    "    np.linspace(y_min, y_max, 200),\n",
    ")\n",
    "\n",
    "grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "grid_pred = svm_pca.predict(grid_points)\n",
    "grid_pred = grid_pred.reshape(xx.shape)\n",
    "\n",
    "\n",
    "# 3. Build SVM bundle\n",
    "bundle = {\n",
    "    \"model_name\": \"Linear SVM (tuned)\",\n",
    "\n",
    "    # Core evaluation arrays (for confusion matrix, ROC, etc.)\n",
    "    \"y_test\": y_test,\n",
    "    \"y_pred\": y_pred,\n",
    "    \"y_scores\": y_scores,   # use this for ROC curves\n",
    "    \"y_proba\": None,        # LinearSVC has no probabilities\n",
    "\n",
    "    \"confusion_matrix\": cm,\n",
    "\n",
    "    # Scalar performance metrics (for model comparison plots)\n",
    "    \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"precision_macro\": precision_score(y_test, y_pred, average=\"macro\", zero_division=0),\n",
    "    \"recall_macro\": recall_score(y_test, y_pred, average=\"macro\", zero_division=0),\n",
    "    \"f1_macro\": f1_score(y_test, y_pred, average=\"macro\", zero_division=0),\n",
    "\n",
    "    # We skip log_loss / AUC because there are no probabilities\n",
    "    \"log_loss\": None,\n",
    "    \"roc_auc_ovr\": None,\n",
    "\n",
    "    # Hyperparameters\n",
    "    \"params\": final_svm.get_params(),\n",
    "\n",
    "    # For interactive feature explorer\n",
    "    \"feature_names\": X_train.columns.to_numpy() if hasattr(X_train, \"columns\") else None,\n",
    "    \"X_test_sample\": X_test.iloc[:2000] if hasattr(X_test, \"iloc\") else X_test[:2000],\n",
    "\n",
    "    # SVM-specific: PCA-based 2D decision boundary\n",
    "    \"svm_pca_components\": pca.components_,\n",
    "    \"svm_pca_explained_variance_ratio\": pca.explained_variance_ratio_,\n",
    "    \"svm_X_test_pca\": X_test_pca,\n",
    "    \"svm_y_test\": y_test,\n",
    "    \"svm_grid_x\": xx,\n",
    "    \"svm_grid_y\": yy,\n",
    "    \"svm_grid_pred\": grid_pred,\n",
    "}\n",
    "\n",
    "\n",
    "# 4. Save bundle to ../../Results/Visualizations\n",
    "save_path = \"../../Results/Visualizations\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "bundle_filename = os.path.join(save_path, \"svm_bundle.pkl\")\n",
    "\n",
    "with open(bundle_filename, \"wb\") as f:\n",
    "    pickle.dump(bundle, f)\n",
    "\n",
    "print(f\"\\nSVM pickle bundle saved to: {bundle_filename}\")\n",
    "print(\"Bundle keys:\", list(bundle.keys()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
