{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05a7c806",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\hyperopt\\atpe.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, roc_auc_score, confusion_matrix, log_loss\n",
    ")\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe, space_eval \n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "import os\n",
    "import pickle\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe563109",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../../Data/BRFSS_2024_model_ready_train.csv\")\n",
    "test_df  = pd.read_csv(\"../../Data/BRFSS_2024_model_ready_test.csv\")\n",
    "\n",
    "X_train = train_df.drop('DIABETE4', axis=1)\n",
    "y_train = train_df['DIABETE4'].astype(int)\n",
    "\n",
    "X_test = test_df.drop('DIABETE4', axis=1)\n",
    "y_test = test_df['DIABETE4'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db03246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since XBG expects labels starting from 0, we need to map our labels accordingly\n",
    "label_map = {1: 0, 3: 1, 4: 2}\n",
    "\n",
    "y_train_enc = y_train.map(label_map)\n",
    "y_test_enc  = y_test.map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a48b409d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None, num_class=3, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;multi:softmax&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">base_score&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;gbtree&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">callbacks&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bylevel&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bynode&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">device&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;cuda&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">early_stopping_rounds&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">enable_categorical&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">eval_metric&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;mlogloss&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_types&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_weights&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">gamma&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">grow_policy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">interaction_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_bin&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_threshold&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_to_onehot&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_delta_step&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaves&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">missing&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotone_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_strategy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">sampling_method&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;gradient_based&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scale_pos_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tree_method&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;approx&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validate_parameters&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbosity&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_class',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_class&nbsp;</td>\n",
       "            <td class=\"value\">3</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device='cuda', early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='mlogloss',\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None, num_class=3, ...)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_info = xgb.build_info()\n",
    "use_cuda = build_info.get(\"USE_CUDA\", False)\n",
    "device = \"cuda\" if use_cuda else \"cpu\"\n",
    "\n",
    "xgb_clf = XGBClassifier(\n",
    "    device = device,\n",
    "    tree_method='approx',\n",
    "    booster='gbtree',\n",
    "    objective='multi:softmax',\n",
    "    sampling_method='gradient_based',\n",
    "    eval_metric='mlogloss',\n",
    "    num_class=3,\n",
    "    random_state=42,\n",
    "    validate_parameters=True\n",
    ")\n",
    "xgb_clf.fit(X_train, y_train_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05429485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\core.py:774: UserWarning: [01:26:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:62: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE MODEL PERFORMANCE\n",
      "Accuracy: 0.8359\n",
      "Precision (macro): 0.4614\n",
      "Recall (macro): 0.3961\n",
      "F1 Score (macro): 0.4063\n",
      "Log Loss: 0.4312\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.22      0.31     13162\n",
      "           1       0.86      0.97      0.91     75226\n",
      "           2       0.00      0.00      0.00      2261\n",
      "\n",
      "    accuracy                           0.84     90649\n",
      "   macro avg       0.46      0.40      0.41     90649\n",
      "weighted avg       0.79      0.84      0.80     90649\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 2889 10272     1]\n",
      " [ 2341 72884     1]\n",
      " [  236  2025     0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_baseline = xgb_clf.predict(X_test)\n",
    "y_proba_baseline = xgb_clf.predict_proba(X_test)\n",
    "\n",
    "print(\"BASELINE MODEL PERFORMANCE\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_enc, y_pred_baseline):.4f}\")\n",
    "print(f\"Precision (macro): {precision_score(y_test_enc, y_pred_baseline, average='macro', zero_division=0):.4f}\")\n",
    "print(f\"Recall (macro): {recall_score(y_test_enc, y_pred_baseline, average='macro', zero_division=0):.4f}\")\n",
    "print(f\"F1 Score (macro): {f1_score(y_test_enc, y_pred_baseline, average='macro', zero_division=0):.4f}\")\n",
    "print(f\"Log Loss: {log_loss(y_test_enc, y_proba_baseline):.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_enc, y_pred_baseline, zero_division=0))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test_enc, y_pred_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a198ee7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:225: UserWarning: [01:36:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  return getattr(self.bst, name)(*args, **kwargs)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [01:36:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [01:36:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [01:36:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [01:36:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [25:02<208:16:18, 1502.56s/trial, best loss: -0.8949303167790763]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:225: UserWarning: [02:01:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  return getattr(self.bst, name)(*args, **kwargs)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [02:01:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [02:01:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [02:01:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [02:01:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/500 [36:11<140:02:10, 1012.31s/trial, best loss: -0.9019637089990209]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:225: UserWarning: [02:12:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  return getattr(self.bst, name)(*args, **kwargs)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [02:12:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [02:12:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [02:12:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [02:12:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/500 [1:00:57<169:35:40, 1228.45s/trial, best loss: -0.9019637089990209]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:225: UserWarning: [02:37:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  return getattr(self.bst, name)(*args, **kwargs)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [02:37:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [02:37:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [02:37:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [02:37:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/500 [1:11:08<135:41:05, 984.81s/trial, best loss: -0.9019637089990209] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:225: UserWarning: [02:47:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  return getattr(self.bst, name)(*args, **kwargs)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [02:47:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [02:47:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [02:47:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [02:47:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/500 [1:36:44<162:43:37, 1183.47s/trial, best loss: -0.9019637089990209]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:225: UserWarning: [03:13:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  return getattr(self.bst, name)(*args, **kwargs)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [03:13:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [03:13:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [03:13:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [03:13:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/500 [1:45:23<131:24:58, 957.69s/trial, best loss: -0.9020534215381415] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:225: UserWarning: [03:22:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  return getattr(self.bst, name)(*args, **kwargs)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [03:22:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [03:22:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [03:22:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [03:22:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 7/500 [1:52:36<107:37:54, 785.95s/trial, best loss: -0.9020534215381415]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:225: UserWarning: [03:29:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  return getattr(self.bst, name)(*args, **kwargs)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [03:29:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [03:29:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [03:29:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [03:29:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 8/500 [2:45:17<210:44:57, 1542.07s/trial, best loss: -0.9020534215381415]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:225: UserWarning: [04:21:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  return getattr(self.bst, name)(*args, **kwargs)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [04:21:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [04:21:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [04:22:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [04:22:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 9/500 [3:00:21<183:07:21, 1342.65s/trial, best loss: -0.9020534215381415]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:225: UserWarning: [04:36:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  return getattr(self.bst, name)(*args, **kwargs)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [04:37:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [04:37:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [04:37:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [04:37:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10/500 [3:16:21<166:39:23, 1224.42s/trial, best loss: -0.9235780306387502]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:225: UserWarning: [04:52:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  return getattr(self.bst, name)(*args, **kwargs)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [04:53:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [04:53:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [04:53:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [04:53:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 11/500 [3:24:54<136:44:49, 1006.73s/trial, best loss: -0.9235780306387502]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:225: UserWarning: [05:01:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  return getattr(self.bst, name)(*args, **kwargs)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [05:01:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [05:01:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [05:01:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [05:01:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 12/500 [3:42:26<138:20:55, 1020.61s/trial, best loss: -0.9235780306387502]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:225: UserWarning: [05:19:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  return getattr(self.bst, name)(*args, **kwargs)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [05:19:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [05:19:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [05:19:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [05:19:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 13/500 [4:12:49<170:57:24, 1263.75s/trial, best loss: -0.9235780306387502]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:225: UserWarning: [05:49:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  return getattr(self.bst, name)(*args, **kwargs)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [05:49:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [05:49:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [05:49:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [05:49:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 14/500 [5:20:21<284:18:25, 2105.98s/trial, best loss: -0.9235780306387502]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:225: UserWarning: [06:57:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  return getattr(self.bst, name)(*args, **kwargs)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [06:57:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [06:57:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [06:57:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [06:57:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 15/500 [5:31:50<226:08:35, 1678.59s/trial, best loss: -0.9235780306387502]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:225: UserWarning: [07:08:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  return getattr(self.bst, name)(*args, **kwargs)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [07:08:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [07:08:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [07:08:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [07:08:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 16/500 [5:39:30<176:21:52, 1311.80s/trial, best loss: -0.9235780306387502]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:225: UserWarning: [07:16:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  return getattr(self.bst, name)(*args, **kwargs)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [07:16:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [07:16:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [07:16:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [07:16:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 17/500 [5:49:13<146:37:10, 1092.82s/trial, best loss: -0.9235780306387502]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:225: UserWarning: [07:25:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  return getattr(self.bst, name)(*args, **kwargs)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [07:25:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [07:25:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [07:25:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [07:25:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 18/500 [6:18:56<174:04:53, 1300.19s/trial, best loss: -0.9235780306387502]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:225: UserWarning: [07:55:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  return getattr(self.bst, name)(*args, **kwargs)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [07:55:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [07:55:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [07:55:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [07:55:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 19/500 [6:29:02<145:51:52, 1091.71s/trial, best loss: -0.9235780306387502]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:225: UserWarning: [08:05:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  return getattr(self.bst, name)(*args, **kwargs)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [08:05:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [08:05:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [08:05:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n",
      "C:\\Users\\premr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\xgboost\\training.py:231: UserWarning: [08:05:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"early_stopping_rounds\", \"importance_type\", \"n_estimators\" } are not used.\n",
      "\n",
      "  self.bst.update(self.dtrain, iteration, fobj)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 20/500 [6:35:30<158:12:03, 1186.51s/trial, best loss: -0.9235780306387502]\n",
      "The best hyperparameters are : \n",
      "{'booster': 'gbtree', 'colsample_bylevel': 0.8159635108371548, 'colsample_bynode': 0.5299536281521451, 'colsample_bytree': 0.5641922668956789, 'device': 'cuda', 'early_stopping_rounds': 50, 'eta': 0.606149561815803, 'gamma': 12.311276116496273, 'grow_policy': 'lossguide', 'importance_type': 'total_cover', 'max_bin': 512, 'max_delta_step': 10, 'max_depth': 6, 'max_leaves': 0, 'min_child_weight': np.int64(40), 'n_estimators': np.int64(3000), 'num_class': 3, 'objective': 'multi:softmax', 'reg_alpha': 3.7453098585029405, 'reg_lambda': 0.6301347956250979, 'sampling_method': 'gradient_based', 'seed': 42, 'subsample': 0.9880042450184583, 'tree_method': 'approx', 'validate_parameters': True}\n"
     ]
    }
   ],
   "source": [
    "search_space = {\n",
    "    'max_depth': hp.choice(\"max_depth\", [4, 6, 8, 10, 12]),\n",
    "    'min_child_weight' : hp.choice(\"min_child_weight\", np.arange(10,100,10,dtype='int')),\n",
    "    'max_leaves': hp.choice(\"max_leaves\", [0, 16, 32, 64, 128, 256]),\n",
    "    'max_bin' : hp.choice(\"max_bin\", [256,512]),\n",
    "    'eta'      : hp.uniform(\"eta\", 0, 1),\n",
    "    'n_estimators': hp.choice(\"n_estimators\", np.arange(1000,5000,1000,dtype='int')),\n",
    "    'max_delta_step' : hp.choice(\"max_delta_step\", [0, 1, 2, 5, 10]),\n",
    "    'subsample' : hp.uniform(\"subsample\",0.5,1),\n",
    "    'colsample_bytree': hp.uniform(\"colsample_bytree\", 0.5,1),\n",
    "    'colsample_bynode': hp.uniform(\"colsample_bynode\", 0.5,1), \n",
    "    'colsample_bylevel': hp.uniform(\"colsample_bylevel\", 0.5,1),\n",
    "    'gamma'    : hp.uniform(\"gamma\", 0, 10e1),\n",
    "    'reg_alpha': hp.uniform(\"reg_alpha\", 10e-7, 10),\n",
    "    'reg_lambda' : hp.uniform(\"reg_lambda\", 0,1),\n",
    "    'early_stopping_rounds' : hp.choice(\"early_stopping_rounds\", [50,100,200]),\n",
    "    'grow_policy' : hp.choice(\"grow_policy\", ['depthwise','lossguide']),\n",
    "    'importance_type' : hp.choice(\"importance_type\", ['gain','weight','cover','total_gain','total_cover']),\n",
    "    'objective' : 'multi:softmax',\n",
    "    'eval_metric' : 'logloss',\n",
    "    'seed' : 42,\n",
    "    'device' : device,\n",
    "    'tree_method' : 'approx',\n",
    "    'booster' : 'gbtree',\n",
    "    'objective' : 'multi:softmax',\n",
    "    'sampling_method' : 'gradient_based',\n",
    "    'eval_metric' : 'mlogloss',\n",
    "    'num_class' : 3,\n",
    "    'validate_parameters' : True\n",
    "}\n",
    "\n",
    "dtrain_clf = xgb.DMatrix(X_train, y_train_enc, enable_categorical = True)\n",
    "\n",
    "def xgb_objective(space):\n",
    "  results = xgb.cv(space, \n",
    "                   dtrain=dtrain_clf,\n",
    "                   num_boost_round=500,\n",
    "                   nfold=5, \n",
    "                   stratified=True,  \n",
    "                   early_stopping_rounds=20,\n",
    "                   metrics = ['mlogloss','auc','aucpr','merror'])\n",
    "  \n",
    "  best_score = results['test-auc-mean'].max()\n",
    "  return {'loss':-best_score, 'status': STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "best_hyperparams = fmin(fn=xgb_objective, space=search_space,algo=tpe.suggest,max_evals=500,trials=trials, return_argmin=False, early_stop_fn=no_progress_loss(10))\n",
    "best_params = best_hyperparams.copy()\n",
    "\n",
    "if 'eval_metric' in best_params:\n",
    "  best_params = {key:best_params[key] for key in best_params if key!='eval_metric'}\n",
    "\n",
    "print(\"The best hyperparameters are : \")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4242fc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST MODEL PERFORMANCE\n",
      "Accuracy: 0.8360\n",
      "Precision (macro): 0.6281\n",
      "Recall (macro): 0.3997\n",
      "F1 Score (macro): 0.4105\n",
      "Log Loss: 0.4354\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.23      0.32     13162\n",
      "           1       0.86      0.97      0.91     75226\n",
      "           2       0.50      0.00      0.00      2261\n",
      "\n",
      "    accuracy                           0.84     90649\n",
      "   macro avg       0.63      0.40      0.41     90649\n",
      "weighted avg       0.80      0.84      0.80     90649\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 3049 10112     1]\n",
      " [ 2491 72735     0]\n",
      " [  243  2017     1]]\n"
     ]
    }
   ],
   "source": [
    "del best_params['early_stopping_rounds']\n",
    "\n",
    "xgb_best = XGBClassifier(**best_params)\n",
    "xgb_best.fit(X_train, y_train_enc)\n",
    "\n",
    "y_pred_best = xgb_best.predict(X_test)\n",
    "y_proba_best = xgb_best.predict_proba(X_test)\n",
    "\n",
    "print(\"BEST MODEL PERFORMANCE\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_enc, y_pred_best):.4f}\")\n",
    "print(f\"Precision (macro): {precision_score(y_test_enc, y_pred_best, average='macro', zero_division=0):.4f}\")\n",
    "print(f\"Recall (macro): {recall_score(y_test_enc, y_pred_best, average='macro', zero_division=0):.4f}\")\n",
    "print(f\"F1 Score (macro): {f1_score(y_test_enc, y_pred_best, average='macro', zero_division=0):.4f}\")\n",
    "print(f\"Log Loss: {log_loss(y_test_enc, y_proba_best):.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_enc, y_pred_best, zero_division=0))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test_enc, y_pred_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9baeb26-af1e-450b-8a08-5c87a4cd9483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE PICKLE BUNDLE FOR XGBOOST MODEL (xgb_best)\n",
    "\n",
    "# 1. Core predictions & confusion matrix\n",
    "# Uses tuned XGBoost model: xgb_best\n",
    "# and encoded labels: y_test_enc\n",
    "\n",
    "y_pred = y_pred_best          # from the notebook\n",
    "y_proba = y_proba_best        # from the notebook\n",
    "y_test = y_test_enc           # use encoded labels (0,1,2)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "# 2. Feature names and X_test sample for explorer\n",
    "if hasattr(X_train, \"columns\"):\n",
    "    feature_names = X_train.columns.to_numpy()\n",
    "else:\n",
    "    feature_names = np.array([f\"feature_{i}\" for i in range(X_train.shape[1])])\n",
    "\n",
    "# sample of X_test for interactive explorer & SHAP\n",
    "if hasattr(X_test, \"iloc\"):\n",
    "    X_test_sample = X_test.iloc[:2000]\n",
    "else:\n",
    "    X_test_sample = X_test[:2000]\n",
    "\n",
    "\n",
    "# 3. Gain-based feature importance (XGBoost default = 'gain')\n",
    "xgb_gain_importance = xgb_best.feature_importances_   # 1D array, per feature\n",
    "\n",
    "\n",
    "# 4. SHAP values for summary plot\n",
    "# Use TreeExplainer on a subset of X_test to keep size manageable\n",
    "try:\n",
    "    explainer = shap.TreeExplainer(xgb_best)\n",
    "    X_shap = X_test_sample\n",
    "    xgb_shap_values = explainer.shap_values(X_shap)\n",
    "    xgb_shap_expected_value = explainer.expected_value\n",
    "except Exception as e:\n",
    "    print(\"Warning: SHAP computation failed, storing None. Error:\", e)\n",
    "    X_shap = None\n",
    "    xgb_shap_values = None\n",
    "    xgb_shap_expected_value = None\n",
    "\n",
    "\n",
    "# 5. Build bundle dictionary with everything we need later\n",
    "bundle = {\n",
    "    \"model_name\": \"XGBoost (tuned)\",\n",
    "\n",
    "    # Core evaluation arrays (for common visualizations) \n",
    "    \"y_test\": y_test,\n",
    "    \"y_pred\": y_pred,\n",
    "    \"y_proba\": y_proba,\n",
    "    \"confusion_matrix\": cm,\n",
    "\n",
    "    # Scalar performance metrics (for comparison plots)\n",
    "    \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"precision_macro\": precision_score(y_test, y_pred,\n",
    "                                      average=\"macro\", zero_division=0),\n",
    "    \"recall_macro\": recall_score(y_test, y_pred,\n",
    "                                 average=\"macro\", zero_division=0),\n",
    "    \"f1_macro\": f1_score(y_test, y_pred,\n",
    "                         average=\"macro\", zero_division=0),\n",
    "    \"log_loss\": log_loss(y_test, y_proba),\n",
    "    \"roc_auc_ovr\": roc_auc_score(y_test, y_proba, multi_class=\"ovr\"),\n",
    "\n",
    "    # Hyperparameters\n",
    "    \"params\": xgb_best.get_params(),\n",
    "\n",
    "    # XGBoost-specific: gain-based feature importance\n",
    "    \"xgb_feature_importance_gain\": xgb_gain_importance,\n",
    "    \"xgb_feature_names\": feature_names,\n",
    "\n",
    "    # SHAP summary support\n",
    "    \"xgb_shap_values\": xgb_shap_values,\n",
    "    \"xgb_shap_expected_value\": xgb_shap_expected_value,\n",
    "    \"xgb_shap_X\": X_shap,\n",
    "\n",
    "    # Common keys for interactive feature explorer\n",
    "    \"feature_names\": feature_names,\n",
    "    \"X_test_sample\": X_test_sample,\n",
    "\n",
    "    # Optional: store the trained model itself\n",
    "    \"xgb_best_model\": xgb_best,\n",
    "}\n",
    "\n",
    "\n",
    "# 6. Save bundle to ../../Results/Visualizations\n",
    "save_path = \"../../Results/Visualizations\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "bundle_filename = os.path.join(save_path, \"xgb_bundle.pkl\")\n",
    "\n",
    "with open(bundle_filename, \"wb\") as f:\n",
    "    pickle.dump(bundle, f)\n",
    "\n",
    "print(f\"\\nXGBoost pickle bundle saved to:\\n{bundle_filename}\")\n",
    "print(\"Bundle keys:\", list(bundle.keys()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
